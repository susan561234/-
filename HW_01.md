# 作業 第一題

遷移式學習基本概念:
遷移學習是一種機器學習的方法，它允許我們利用一個在大量數據上預訓練的模型,並將其知識遷移到一個新的、通常較小的的數據集上解決相關任務。一般作法如下:
1. 選擇一个預訓練模型：从大量數據上訓練好的深度神經網路，如 ImageNet 上的 ResNet、VGG、Inception 等。
2. 移除預訓練模型的輸出層：預訓練模型得輸出層通常是針對原始任務設計的。移除輸出層，使得可以添加式核心任務的自訂義輸出層。
3. 添加自定義層：為目標任務添加一個或多個新的輸出層，例如全連接層、卷積層等。
4. 凍結預訓練模型的層：為了只訓練自訂義的輸出層，需要凍結預訓練模型的其他層，防止在訓練過程中更新他們的權重。
5. 訓練和評估：使用目標任務的訓練數據訓練新添加的自訂義層，並評估模型在驗證或測試數據上的性能。


**利用Resnet50遷移式學習做貓狗辨識**

1. 載入模型
2. 凍結參數
3. 添加自訂義層(分類器神經網路)
4. 編譯
5. 訓練
6. 評估

**資料來源:kaggle貓狗辨識**
訓練
拿取貓狗前各3500張共7000張作訓練
拿取貓狗後各2000張共4000張作驗證
拿取貓狗中間個777張共1544做評估
預測
拿取test資料夾中前100張做預測

```
from google.colab import drive

input_size = (224, 224)
batch_size = 32
train_path = '/content/drive/MyDrive/Colab Notebooks/train'
test_path = '/content/drive/MyDrive/Colab Notebooks/test'

train_datagen = ImageDataGenerator()
train_generator = train_datagen.flow_from_directory(train_path,target_size=input_size)
test_datagen = ImageDataGenerator()
test_generator = test_datagen.flow_from_directory(test_path,target_size=input_size)
```

**載入模型**
```
# 載入預訓練的 ResNet50 模型，不包含最後一層
base_model = ResNet50(weights='imagenet', include_top=False)
```
**添加自定義層**
```
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(2, activation='sigmoid')(x)
```

**定義完整模型**
```
model = Model(inputs=base_model.input, outputs=predictions)
```

**凍結** 
```
for layer in base_model.layers:
    layer.trainable = False
```
**編譯模型**
```
model.compile(optimizer=Adam(learning_rate=0.001), loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])

print(model.summary())
```
**訓練**
```
def plot_history(history):
    # 繪製訓練與驗證的損失值
    plt.figure()
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    # 繪製訓練與驗證的準確率
    plt.figure()
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.show()

epochs = 10

history = model.fit(train_generator,
          validation_data=test_generator,
          steps_per_epoch=100,
          validation_steps=1,
          epochs=epochs)
plot_history(history)
```

![](https://i.imgur.com/iVcNqAk.png)


**評估**

```
test_path = '/content/drive/MyDrive/Colab Notebooks/test1'

pre_datagen = ImageDataGenerator()

pre_generator = pre_datagen.flow_from_directory(test_path,
                          target_size=input_size)
loss,accuracy = model.evaluate(pre_generator_,verbose=0)
print("測試資料集的準確度 = {:.2f}".format(accuracy))
```

![](https://i.imgur.com/DZSSdcC.png)


對資料夾內100張圖片做辨識，輸出predictions.csv

```
from tensorflow.keras.applications.inception_v3 import preprocess_input
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array
import csv
image_folder = "/content/drive/MyDrive/Colab Notebooks/pre"
output_file = "predictions.csv"
image_files = sorted(os.listdir(image_folder), key=lambda x: int(x.split('.')[0]))
with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
  csv_writer = csv.writer(csvfile)
  csv_writer.writerow(['編號','預測標籤',"名稱","檔案名稱"])
  for idx, image_name in enumerate(image_files, start=1):
      print(image_name)
      image_path = os.path.join(image_folder, image_name)
      img_array = load_img(image_path,target_size=(224,224))
      x = img_to_array(img_array)
      x = np.expand_dims(x,axis=0)    
      pre = model.predict(x)
      if "29" in image_name:
        print(pre)
      if pre[0][0]>pre[0][1]:
        csv_writer.writerow([idx,0,"cat",image_name])
      else:
        csv_writer.writerow([idx,1,"dog",image_name])
```

在輸出的csv檔中,只有一項辨識錯誤
![](https://i.imgur.com/IrsBedR.png)


![](https://i.imgur.com/xtuzYMy.png)

查看辨識的機率[[貓:0.959698 ,狗:0.10785121]]

訓練資料集較少側面資料，應增加類似圖片訓練提升模型泛化能力